{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UKKO - Transformer model for tabular longitudonal data \n",
    "\n",
    "Author: Eric Fey (eric.fey@hus.fi)  \n",
    "First version: 2025-03-01\n",
    "\n",
    "This **`ukko_get_started`** notebook shows the basic cababilities of the ukko dual attention model:\n",
    "- Predict next timepoints in timourse data. Example: sine wave.\n",
    "- Classification based on sine wave feature data as example.\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "UKKO is a PyTorch-based package for analyzing longitudinal tabular data using transformer-based deep learning models. It provides:\n",
    "\n",
    "- **Dual Attention Architecture**: Combines feature-wise and temporal attention mechanisms\n",
    "- **Multiple Model Types**: \n",
    "  - Regression models for time series prediction\n",
    "  - Classification models for feature-wise classification\n",
    "  - Survival analysis models based on Cox proportional hazards\n",
    "- **Built-in Visualization**: Tools for model interpretation and performance analysis\n",
    "\n",
    "### Installation\n",
    "\n",
    "1. Install hatchling package manager:\n",
    "```bash\n",
    "pip install hatchling\n",
    "```\n",
    "\n",
    "2. Install ukko in development mode:\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "3. Go :smiley:\n",
    "\n",
    "### Quick Start\n",
    "\n",
    "```python\n",
    "import ukko\n",
    "from ukko.core import DualAttentionRegressor\n",
    "from ukko.data import SineWaveDataset\n",
    "\n",
    "# Create synthetic dataset\n",
    "dataset = SineWaveDataset(\n",
    "    n_samples=1000,\n",
    "    n_features=5,\n",
    "    sequence_length=32,\n",
    "    prediction_length=5\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = DualAttentionRegressor(\n",
    "    n_features=5,\n",
    "    time_steps=32,\n",
    "    d_model=128\n",
    ")\n",
    "```\n",
    "\n",
    "### Contents\n",
    "\n",
    "- TBA\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Python 3.8+\n",
    "- PyTorch 2.0+\n",
    "- NumPy\n",
    "- Pandas\n",
    "- Matplotlib\n",
    "- Scikit-learn\n",
    "\n",
    "For survival analysis:\n",
    "- Lifelines\n",
    "- Scikit-survival\n",
    "\n",
    "### References\n",
    "\n",
    "- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "- [Deep Learning for Survival Analysis](https://arxiv.org/abs/1910.00199)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention model with residual connectoin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import ukko \n",
    "import importlib\n",
    "import ukko.core\n",
    "import ukko.data\n",
    "\n",
    "importlib.reload(ukko.core)\n",
    "importlib.reload(ukko.data)\n",
    "importlib.reload(ukko.test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ukko installatin and model\n",
    "%run ./tests/tests_core.py\n",
    "model = test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data sine wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import ukko\n",
    "\n",
    "def create_data_loaders(batch_size=32, n_samples=1000, n_features=15,\n",
    "                       sequence_length=100, prediction_length=5):\n",
    "    \"\"\"Create train, validation, and test data loaders\"\"\"\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = ukko.data.SineWaveDataset(n_samples, n_features, sequence_length, prediction_length)\n",
    "    val_dataset = ukko.data.SineWaveDataset(n_samples//5, n_features, sequence_length, prediction_length, seed=43)\n",
    "    test_dataset = ukko.data.SineWaveDataset(n_samples//5, n_features, sequence_length, prediction_length, seed=44)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def test_model_with_sine_data():\n",
    "    # Parameters\n",
    "    batch_size = 32\n",
    "    n_samples = 1000\n",
    "    n_features = 3\n",
    "    sequence_length = 32\n",
    "    prediction_length = 5\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        batch_size=batch_size,\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        sequence_length=sequence_length,\n",
    "        prediction_length=prediction_length\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    model = ukko.core.DualAttentionRegressor(\n",
    "        n_features=n_features,\n",
    "        time_steps=sequence_length,\n",
    "        d_model=128,\n",
    "        n_heads=8,\n",
    "        dropout=0.1\n",
    "    )\n",
    "    #model = []\n",
    "\n",
    "\n",
    "    # Plot example\n",
    "    dataset = ukko.data.SineWaveDataset(n_samples, n_features, sequence_length, prediction_length)\n",
    "    ukko.data.plot_example_dataset(dataset, sample_idx=1)\n",
    "\n",
    "    return model, train_loader, val_loader, test_loader\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "model, train_loader, val_loader, test_loader = test_model_with_sine_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ukko.data)\n",
    "\n",
    "# Parameters\n",
    "batch_size = 32\n",
    "n_samples = 1400\n",
    "n_features = 5\n",
    "sequence_length = 32\n",
    "prediction_length = 5\n",
    "\n",
    "# Create dataset:\n",
    "dataset = ukko.data.SineWaveDataset(n_samples, n_features, sequence_length, prediction_length,\n",
    "                                   base_freq=0.05, noise_level=0.2)\n",
    "ukko.data.plot_example_dataset(dataset, sample_idx=0, feature_idx=0)\n",
    "ukko.data.plot_example_dataset(dataset, sample_idx=1, feature_idx=0)\n",
    "ukko.data.plot_example_dataset(dataset, sample_idx=0, feature_idx=1)\n",
    "ukko.data.plot_example_dataset(dataset, sample_idx=1, feature_idx=1)\n",
    "ukko.data.plot_example_dataset(dataset, sample_idx=0, feature_idx=2)\n",
    "ukko.data.plot_example_dataset(dataset, sample_idx=1, feature_idx=2)\n",
    "\n",
    "trainset = dataset.Subset(range(0,1000))\n",
    "valset = dataset.Subset(range(1000,1200))\n",
    "testset = dataset.Subset(range(1200,1400))\n",
    "\n",
    "print(f\"Trainset: {trainset.__len__()}\")\n",
    "print(f\"Trainset: {trainset.getdim()}\")\n",
    "print(f\"Valset:   {valset.getdim()}\")\n",
    "print(f\"Testset:  {testset.getdim()}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ukko.core.DualAttentionRegressor(\n",
    "#model = ukko.core.DualAttentionModelOld(\n",
    "    n_features=n_features,\n",
    "    time_steps=sequence_length,\n",
    "    d_model=128,\n",
    "    n_heads=16,\n",
    "    dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "for x, y in islice(val_loader, 2):\n",
    "  print(x.shape)\n",
    "  print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sine_model(model, train_loader, val_loader, epochs=50, lr=0.001, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output, _, _ = model(x)\n",
    "            #loss = criterion(output, y[:, :, 0])  # Compare with first time step of prediction\n",
    "            loss = criterion(output, y)  # y is only one timepoint 5 or 4 steps ahead\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output, _, _ = model(x)\n",
    "                #val_loss += criterion(output, y[:, :, 0]).item()\n",
    "                val_loss += criterion(output, y).item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_sine_model.pt')\n",
    "\n",
    "# Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model, train_loader, val_loader, test_loader = test_model_with_sine_data()\n",
    "train_sine_model(model, train_loader, val_loader, epochs = 50, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "importlib.reload(ukko.data)\n",
    "\n",
    "def visualize_predictions(model, test_loader, device='cuda', num_examples=3):\n",
    "    model.eval()\n",
    "\n",
    "    # Get some test examples\n",
    "    x, y = next(iter(test_loader))\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        predictions, feat_attn, time_attn = model(x)\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        x = x.cpu().numpy()\n",
    "        y = y.cpu().numpy()\n",
    "\n",
    "    # Plot 3 different features\n",
    "    for i, feature_idx in enumerate([0,1,2]):#([0, 7, 14]):  # Beginning, middle, and end features\n",
    "        \n",
    "        # Plot multiple features for a few examples\n",
    "        for example_idx in range(min(num_examples, x.shape[0])):\n",
    "            \n",
    "            fig = ukko.data.plot_example_dataset(testset, example_idx, feature_idx)\n",
    "            ax = fig.axes[0]\n",
    "            \n",
    "            # Time of prediction \n",
    "            time_input = np.arange(x.shape[2])\n",
    "            #time_target = np.arange(x.shape[2], x.shape[2] + y.shape[2])\n",
    "            time_target = [x.shape[2] + prediction_length - 1]\n",
    "            \n",
    "            # Plot prediction\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            ax.scatter(time_target[0], predictions[example_idx, feature_idx].item(),\n",
    "                       marker = '^', label='Model Prediction', color='red', s=100, \n",
    "                      zorder=5)\n",
    "            \n",
    "            ax.set_title(f'Example {example_idx}, Feature {feature_idx}')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "        \n",
    "    # Plot data vs predicted & groundtruth vs predicted\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    # data vs predicted\n",
    "    plt.subplot(1, 2, 1)\n",
    "    print(f\"Data: {y.shape}\")\n",
    "    print(f\"Predictions: {predictions.shape}\")\n",
    "    np.random.seed(1)\n",
    "    for col in range(y.shape[1]):\n",
    "      plt.scatter(predictions[:,col], y[:,col],\n",
    "                  c=np.random.rand(3,), label=f'Feature {col}', alpha=0.5)\n",
    "    # Add perfect line\n",
    "    plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Data vs Predicted')\n",
    "    plt.legend()\n",
    "\n",
    "    # Visualize attention weights\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Feature attention weights\n",
    "    plt.subplot(1, 2, 1)\n",
    "    feat_attn_avg = feat_attn.mean(dim=(0, 1)).cpu().numpy()\n",
    "    plt.imshow(feat_attn_avg, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title('Feature Attention Weights')\n",
    "    plt.xlabel('Target Feature')\n",
    "    plt.ylabel('Source Feature')\n",
    "\n",
    "    # Time attention weights\n",
    "    plt.subplot(1, 2, 2)\n",
    "    time_attn_avg = time_attn.mean(dim=(0, 1)).cpu().numpy()\n",
    "    plt.imshow(time_attn_avg, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title('Time Attention Weights')\n",
    "    plt.xlabel('Target Time Step')\n",
    "    plt.ylabel('Source Time Step')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    total_mse = 0\n",
    "    total_mae = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            predictions, _, _ = model(x)\n",
    "\n",
    "            # Calculate MSE and MAE\n",
    "            #mse = criterion(predictions, y[:, :, 0])\n",
    "            #mae = torch.abs(predictions - y[:, :, 0]).mean()\n",
    "            mse = criterion(predictions, y)\n",
    "            mae = torch.abs(predictions - y).mean()\n",
    "\n",
    "            total_mse += mse.item()\n",
    "            total_mae += mae.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_mse = total_mse / num_batches\n",
    "    avg_mae = total_mae / num_batches\n",
    "\n",
    "    print(f\"Test Set Metrics:\")\n",
    "    print(f\"Average MSE: {avg_mse:.4f}\")\n",
    "    print(f\"Average MAE: {avg_mae:.4f}\")\n",
    "    print(f\"RMSE: {np.sqrt(avg_mse):.4f}\")\n",
    "\n",
    "    return avg_mse, avg_mae\n",
    "\n",
    "def main():\n",
    "    # Parameters\n",
    "    # batch_size = 32\n",
    "    # n_samples = 1000\n",
    "    # n_features = 3\n",
    "    # sequence_length = 32\n",
    "    # prediction_length = 5\n",
    "\n",
    "    # Create data loaders\n",
    "    # train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    #     batch_size=batch_size,\n",
    "    #     n_samples=n_samples,\n",
    "    #     n_features=n_features,\n",
    "    #     sequence_length=sequence_length,\n",
    "    #     prediction_length=prediction_length\n",
    "    # )\n",
    "\n",
    "    # Initialize model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # model = ukko.core.DualAttentionModel(\n",
    "    #     n_features=n_features,\n",
    "    #     time_steps=sequence_length,\n",
    "    #     d_model=128,\n",
    "    #     n_heads=8,\n",
    "    #     dropout=0.1\n",
    "    # ).to(device)\n",
    "\n",
    "    # Load best model weights\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('best_sine_model.pt'))\n",
    "        print(\"Loaded best model weights successfully!\")\n",
    "    except:\n",
    "        print(\"No saved model found. Please train the model first.\")\n",
    "        return\n",
    "\n",
    "    # Evaluate model\n",
    "    mse, mae = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    # Visualize results\n",
    "    visualize_predictions(model, test_loader, device)\n",
    "\n",
    "    # Save a timestamp of when these results were generated\n",
    "    timestamp = \"2025-03-01 10:01:16\"  # Using the provided timestamp\n",
    "    user = \"eric-fey-hus\"\n",
    "\n",
    "    # Save results to a file\n",
    "    with open('model_results.txt', 'w') as f:\n",
    "        f.write(f\"Results generated on: {timestamp}\\n\")\n",
    "        f.write(f\"Generated by user: {user}\\n\")\n",
    "        f.write(f\"Model Performance Metrics:\\n\")\n",
    "        f.write(f\"MSE: {mse:.4f}\\n\")\n",
    "        f.write(f\"MAE: {mae:.4f}\\n\")\n",
    "        f.write(f\"RMSE: {np.sqrt(mse):.4f}\\n\")\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First reload modules to ensure latest changes\n",
    "import importlib\n",
    "import ukko.core\n",
    "import ukko.data\n",
    "importlib.reload(ukko.core)\n",
    "importlib.reload(ukko.data)\n",
    "\n",
    "# Import test function \n",
    "from ukko.core import DualAttentionClassifier, visualize_predictions\n",
    "from ukko.data import SineWaveDataset\n",
    "\n",
    "# Run the test\n",
    "#from tests.test_dual_attention_classifier import test_dual_attention_classifier\n",
    "#test_dual_attention_classifier()\n",
    "\n",
    "%run ./tests/test_dual_attention_classifier.py\n",
    "model, train_losses, plt1, plt2 = test_dual_attention_classifier(n_epochs = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
