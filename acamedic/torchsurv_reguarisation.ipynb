{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Compare AdamW reg parameter for a fixed architecture that overfits with ADAM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import ukko \n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsurv.loss.cox import neg_partial_log_likelihood\n",
    "from torchsurv.loss.weibull import neg_log_likelihood, log_hazard, survival_function\n",
    "from torchsurv.metrics.brier_score import BrierScore\n",
    "from torchsurv.metrics.cindex import ConcordanceIndex\n",
    "from torchsurv.metrics.auc import Auc\n",
    "#from torchsurv.stats.kaplan_meier import KaplanMeierEstimator\n",
    "# for cuda cleanups:\n",
    "import gc\n",
    "\n",
    "print(\"Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Custom function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses, title: str = \"Cox\") -> None:\n",
    "\n",
    "    #train_losses = torch.stack(train_losses) / train_losses[0]\n",
    "    #val_losses = torch.stack(val_losses) / val_losses[0]\n",
    "    train_losses = np.array(train_losses)\n",
    "    val_losses = np.array(val_losses)\n",
    "    train_losses = train_losses / train_losses[0]\n",
    "    val_losses = val_losses / val_losses[0]\n",
    "\n",
    "    plt.plot(train_losses, label=\"training\")\n",
    "    plt.plot(val_losses, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Normalized loss\")\n",
    "    plt.title(title)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class ukkosurv_dataset(Dataset):\n",
    "    \"\"\" \"Custom dataset for ukko-torcsurv use in df format\"\"\"\n",
    "\n",
    "    # defining values in the constructor\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        #self.df = df\n",
    "        df_x, data_3d = ukko.utils.convert_to_3d_df(df.iloc[:,3:].fillna(-1))\n",
    "        df_y = df_train.iloc[:,:3]\n",
    "        \n",
    "        self.df_y = df_y        # Dataframe with survival data, e.g. OSS_status, OSS_days\n",
    "        self.data_3d = data_3d  # numpy array with 3D feature data: patients, features, time \n",
    "\n",
    "\n",
    "    # Getting data size/length\n",
    "    def __len__(self):\n",
    "        return len(self.data_3d)\n",
    "\n",
    "    # Getting the data samples\n",
    "    def __getitem__(self, idx):\n",
    "        y = self.df_y.iloc[idx,:]\n",
    "        # Targets\n",
    "        event = torch.tensor(y[\"OSS_status\"]).bool()\n",
    "        time = torch.tensor(y[\"OSS_days\"]).float()\n",
    "        # Predictors\n",
    "        x = torch.tensor(self.data_3d[idx,:,:]).float()\n",
    "        return x, (event, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "import copy\n",
    "def train_model_simple(\n",
    "            model,\n",
    "            dataloader_train,\n",
    "            dataloader_val,\n",
    "            optimizer = None,\n",
    "            n_epochs = 100,\n",
    "            learning_rate = 0.01,\n",
    "            device='cuda'\n",
    "        ):\n",
    "\n",
    "    dtype=torch.float32\n",
    "    \n",
    "    # Initialize optimizer if not provided\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Initiate empty list to store the loss on the train and validation sets\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_epoch = 0\n",
    "    best_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Get device and move model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device=device, dtype=dtype)\n",
    "    \n",
    "    # training loop\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0.0 #torch.tensor(0.0)\n",
    "        model = model.to(dtype=dtype, device=device) #\n",
    "        for i, batch in enumerate(dataloader_train):\n",
    "            x, (event, time) = batch\n",
    "            x = x.to(dtype=dtype, device=device, non_blocking=True)\n",
    "            event = event.to(device, non_blocking=True)\n",
    "            time = time.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            log_hz, feature_weights, time_weights = model(x)  # shape = (batchsize, 1)\n",
    "            loss = neg_partial_log_likelihood(log_hz, event, time, reduction=\"mean\").to(dtype=dtype, device=device, non_blocking=True)\n",
    "            #print(f\"loss dtype: {loss.dtype}\")\n",
    "            #print(f\"loss cuda:  {loss.is_cuda}\")\n",
    "            #print(f\"weights dtype: {feature_weights.dtype, time_weights.dtype}\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() #.detach().to(\"cpu\").item()\n",
    "\n",
    "            # Free up memory for unused tensors\n",
    "            del x, event, time, log_hz, feature_weights, time_weights, loss\n",
    "            \n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Reccord loss on train and test sets\n",
    "        epoch_loss /= i + 1\n",
    "        train_losses.append(epoch_loss)\n",
    "        model.eval()\n",
    "        #print(\"Eval mode\")\n",
    "        with torch.no_grad():\n",
    "            x, (event, time) = next(iter(dataloader_val))\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            event = event.to(device, non_blocking=True)\n",
    "            time = time.to(device, non_blocking=True)\n",
    "            log_hz, feature_weights, time_weights = model(x)\n",
    "            val_loss = neg_partial_log_likelihood(log_hz, event, time, reduction=\"mean\").item() #.detach().to(\"cpu\")\n",
    "            val_losses.append(val_loss)\n",
    "            # Save best model based on validation loss\n",
    "            if val_loss < best_loss:\n",
    "                best_epoch = epoch\n",
    "                best_loss = val_loss\n",
    "                best_model_state = copy.deepcopy(model.to('cpu').state_dict())\n",
    "        \n",
    "        del x, event, time, log_hz, feature_weights, time_weights    \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Display progress\n",
    "        if epoch % 1 == 0: #(n_epochs // 5) == 0:\n",
    "            print(f\"    Epoch: {epoch:03}, Training loss: {train_losses[-1]:0.2f}, Validation loss: {val_losses[-1]:0.2f}\")\n",
    "    \n",
    "    # Load best model if validation was used\n",
    "    if dataloader_val and best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    return model, train_losses, val_losses, best_loss, best_epoch #if dataloader_val else avg_train_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tidy data\n",
    "print(\"Loading tidy data\")\n",
    "df_xy = pd.read_csv(\"data/df_xy_synth_v1.csv\")\n",
    "\n",
    "# create train, validation and test datasets: IMPUTE nan: -1\n",
    "df_train = df_xy.fillna(-1)\n",
    "df_test = df_train.sample(n=200, random_state=42)\n",
    "df_train = df_train.drop(df_test.index)\n",
    "df_val = df_train.sample(n=200, random_state=42)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "\n",
    "print(f\"Train: {df_train.shape}\")\n",
    "print(f\"Val  : {df_val.shape}\")\n",
    "print(f\"Test : {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Ukko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Dataloaders: train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ukko)\n",
    "importlib.reload(ukko.utils)\n",
    "\n",
    "# Dataloader\n",
    "BATCH_SIZE = 600\n",
    "dataloader_train = DataLoader(\n",
    "    ukkosurv_dataset(df_train), batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    ukkosurv_dataset(df_val), batch_size=len(df_val), shuffle=False\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    ukkosurv_dataset(df_test), batch_size=len(df_test), shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ukko.core)\n",
    "\n",
    "# Get feature and time dimensions\n",
    "x, (event, time) = next(iter(dataloader_train))\n",
    "num_features, num_timepoints = x.size(1), x.size(2)\n",
    "print(f\"Number of features: {num_features}, Number of timepoints: {num_timepoints}\")\n",
    "\n",
    "# Initialize model\n",
    "# DualAttentionRegressor1(self, n_features, time_steps, d_model=128, n_heads=8, dropout=0.1, n_modules=1)\n",
    "def initmodel():\n",
    "  model = ukko.core.DualAttentionRegressor1(\n",
    "    n_features=num_features,\n",
    "    time_steps=num_timepoints,\n",
    "    d_model=8,\n",
    "    n_heads=4,\n",
    "    n_kv_heads=4,\n",
    "    dropout=0.2,\n",
    "    n_modules=2\n",
    "  )\n",
    "  return model\n",
    "\n",
    "model = initmodel()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Init optimizer for Cox\n",
    "# AdamW is generally preferred over Adam for its weight decay regularization\n",
    "optimizer_noreg = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "optimizer_reg = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-1)\n",
    "\n",
    "\n",
    "# Initiate empty list to store the loss on the train and validation sets\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Get device and move model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = initmodel()\n",
    "model = model.to(device)\n",
    "# Train models\n",
    "trained_model_reg, train_losses_reg, val_losses_reg, val_loss_reg, best_epoch_i_reg = train_model_simple(\n",
    "    model=model,\n",
    "    dataloader_train = dataloader_train,\n",
    "    dataloader_val = dataloader_val, \n",
    "    optimizer=optimizer_reg,\n",
    "    n_epochs=EPOCHS,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "model = initmodel().to(device)\n",
    "trained_model_noreg, train_losses_noreg, val_losses_noreg, val_loss_noreg, best_epoch_i_noreg = train_model_simple(\n",
    "    model=model,\n",
    "    dataloader_train = dataloader_train,\n",
    "    dataloader_val = dataloader_val, \n",
    "    optimizer=optimizer_noreg,\n",
    "    n_epochs=EPOCHS,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "\n",
    "plot_losses(train_losses_reg, val_losses_reg, \"Cox\")\n",
    "print(f\"  Best train and val loss: {min(train_losses_reg):0.3f}, {min(val_losses_reg):0.3f}\")\n",
    "\n",
    "plot_losses(train_losses_noreg, val_losses_noreg, \"Cox\")\n",
    "print(f\"  Best train and val loss: {min(train_losses_noreg):0.3f}, {min(val_losses_noreg):0.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
