{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eric-fey-hus/ukko/blob/main/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7FWUjrfHJZT"
   },
   "source": [
    "# Transforme model for tabular timecourse data\n",
    "\n",
    "## Basic attention model with residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aamrbOJztjQP",
    "outputId": "09ecb784-97c5-4e5c-a8fd-5e0bca86c683"
   },
   "outputs": [],
   "source": [
    "# attention model with residual connectoin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(-2)]\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        seq_len = query.size(1)\n",
    "\n",
    "        Q = self.W_q(query)\n",
    "        K = self.W_k(key)\n",
    "        V = self.W_v(value)\n",
    "\n",
    "        Q = Q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        output = self.W_o(output)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "\n",
    "class DualAttentionModel(nn.Module):\n",
    "    def __init__(self, n_features, time_steps, d_model=128, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(1, d_model)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "\n",
    "        # Feature attention block\n",
    "        self.feature_attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.feature_norm = nn.LayerNorm(d_model)\n",
    "        self.feature_ff = FeedForward(d_model, dropout=dropout)\n",
    "        self.feature_ff_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Time attention block\n",
    "        self.time_attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.time_norm = nn.LayerNorm(d_model)\n",
    "        self.time_ff = FeedForward(d_model, dropout=dropout)\n",
    "        self.time_ff_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Output layers with residual connection\n",
    "        self.output_ff = FeedForward(d_model, dropout=dropout)\n",
    "        self.output_norm = nn.LayerNorm(d_model)\n",
    "        self.fc = nn.Linear(d_model, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, n_features, time_steps]\n",
    "        batch_size, n_features, time_steps = x.shape\n",
    "\n",
    "        # Add channel dimension and project\n",
    "        x = x.unsqueeze(-1)  # [batch_size, n_features, time_steps, 1]\n",
    "        x = self.input_projection(x)  # [batch_size, n_features, time_steps, d_model]\n",
    "\n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoder(x)\n",
    "\n",
    "        # Feature attention block with residual connections\n",
    "        # Reshape for feature attention\n",
    "        x_feat = x.transpose(1, 2).reshape(batch_size * time_steps, n_features, self.d_model)\n",
    "        identity = x_feat\n",
    "\n",
    "        # Feature attention\n",
    "        x_feat, feat_weights = self.feature_attention(x_feat, x_feat, x_feat)\n",
    "        x_feat = identity + self.dropout(x_feat)  # First residual connection\n",
    "        x_feat = self.feature_norm(x_feat)\n",
    "\n",
    "        # Feature feed-forward\n",
    "        identity = x_feat\n",
    "        x_feat = identity + self.dropout(self.feature_ff(x_feat))  # Second residual connection\n",
    "        x_feat = self.feature_ff_norm(x_feat)\n",
    "\n",
    "        # Reshape back\n",
    "        x = x_feat.view(batch_size, time_steps, n_features, self.d_model).transpose(1, 2)\n",
    "\n",
    "        # Time attention block with residual connections\n",
    "        # Reshape for time attention\n",
    "        x_time = x.reshape(batch_size * n_features, time_steps, self.d_model)\n",
    "        identity = x_time\n",
    "\n",
    "        # Time attention\n",
    "        x_time, time_weights = self.time_attention(x_time, x_time, x_time)\n",
    "        x_time = identity + self.dropout(x_time)  # Third residual connection\n",
    "        x_time = self.time_norm(x_time)\n",
    "\n",
    "        # Time feed-forward\n",
    "        identity = x_time\n",
    "        x_time = identity + self.dropout(self.time_ff(x_time))  # Fourth residual connection\n",
    "        x_time = self.time_ff_norm(x_time)\n",
    "\n",
    "        # Reshape back\n",
    "        x = x_time.view(batch_size, n_features, time_steps, self.d_model)\n",
    "\n",
    "        # Global average pooling over time\n",
    "        x = x.mean(dim=2)  # [batch_size, n_features, d_model]\n",
    "\n",
    "        # Final feed-forward with residual connection\n",
    "        identity = x\n",
    "        x = identity + self.dropout(self.output_ff(x))  # Fifth residual connection\n",
    "        x = self.output_norm(x)\n",
    "\n",
    "        # Final projection\n",
    "        x = self.fc(x).squeeze(-1)  # [batch_size, n_features]\n",
    "\n",
    "        return x, feat_weights, time_weights\n",
    "\n",
    "def test_model():\n",
    "    # Example dimensions\n",
    "    batch_size = 32\n",
    "    n_features = 15\n",
    "    time_steps = 10\n",
    "\n",
    "    # Create random input data\n",
    "    x = torch.randn(batch_size, n_features, time_steps)\n",
    "\n",
    "    # Initialize model\n",
    "    model = DualAttentionModel(\n",
    "        n_features=n_features,\n",
    "        time_steps=time_steps,\n",
    "        d_model=128,\n",
    "        n_heads=8,\n",
    "        dropout=0.1\n",
    "    )\n",
    "\n",
    "    # Forward pass\n",
    "    output, feat_attn, time_attn = model(x)\n",
    "\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Feature attention weights shape: {feat_attn.shape}\")\n",
    "    print(f\"Time attention weights shape: {time_attn.shape}\")\n",
    "\n",
    "    return model, output, feat_attn, time_attn\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "model, output, feat_attn, time_attn = test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm1jXSikHlNT"
   },
   "source": [
    "## Test data sine wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "W7w5YweyHbnx",
    "outputId": "c165124b-45cd-427b-e981-dd984d8fc532"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "class SineWaveDataset(Dataset):\n",
    "    def __init__(self, n_samples, n_features, sequence_length, prediction_length=5,\n",
    "                 base_freq=0.1, noise_level=0.2, seed=42):\n",
    "        \"\"\"\n",
    "        Creates sine wave dataset with different phases and amplitudes for each feature\n",
    "\n",
    "        Args:\n",
    "            n_samples: Number of samples in dataset\n",
    "            n_features: Number of features\n",
    "            sequence_length: Length of input sequence\n",
    "            prediction_length: Length of sequence to predict\n",
    "            base_freq: Base frequency of sine waves\n",
    "            noise_level: Standard deviation of Gaussian noise\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "        self.prediction_length = prediction_length\n",
    "\n",
    "        # Create time points\n",
    "        t = np.linspace(0, (sequence_length + prediction_length) * 2 * np.pi,\n",
    "                       sequence_length + prediction_length)\n",
    "\n",
    "        # Generate data for each sample\n",
    "        data = []\n",
    "        groundtruth = []\n",
    "        for _ in range(n_samples):\n",
    "            sample = []\n",
    "            groundtruthsample = []\n",
    "            for f in range(n_features):\n",
    "                # Random phase and amplitude for each feature\n",
    "                phase = np.random.uniform(0, 2 * np.pi)\n",
    "                amplitude = np.random.uniform(0.5, 2.0)\n",
    "\n",
    "                # Generate sine wave with noise\n",
    "                sine_wave = amplitude * np.sin(base_freq * t + phase)\n",
    "                noise = np.random.normal(0, noise_level, len(t))\n",
    "                feature_data = sine_wave + noise\n",
    "\n",
    "                sample.append(feature_data)\n",
    "                groundtruthsample.append(sine_wave)\n",
    "            data.append(sample)\n",
    "            groundtruth.append(groundtruthsample)\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        self.data = torch.FloatTensor(data)  # [n_samples, n_features, sequence_length + prediction_length]\n",
    "        self.groundtruth = torch.FloatTensor(groundtruth)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # data with noise\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx, :, :self.sequence_length]\n",
    "        #y = self.data[idx, :, self.sequence_length:self.sequence_length + self.prediction_length]\n",
    "        y = self.data[idx, :, self.sequence_length + self.prediction_length -1]\n",
    "        return x, y\n",
    "\n",
    "    # groundtruth data:\n",
    "    def __getgtitem__(self, idx):\n",
    "        x = self.groundtruth[idx, :, :self.sequence_length]\n",
    "        y = self.groundtruth[idx, :, self.sequence_length:self.sequence_length + self.prediction_length]\n",
    "        return x, y\n",
    "\n",
    "def plot_example(dataset, sample_idx=0, feature_idx=0):\n",
    "    \"\"\"Plot an example from the dataset with markers\"\"\"\n",
    "    x, y = dataset[sample_idx]\n",
    "    xgt, ygt = dataset.__getgtitem__(sample_idx)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot data sample with noise\n",
    "    # Plot input sequence with markers\n",
    "    plt.plot(range(len(x[feature_idx])), x[feature_idx],\n",
    "             'o', label='Input sequence', color='blue',\n",
    "             markersize=4, markerfacecolor='white', markeredgewidth=1)\n",
    "\n",
    "    # Plot target sequence with different markers\n",
    "    #plt.plot(range(len(x[feature_idx]), len(x[feature_idx]) + len(y[feature_idx])),\n",
    "    #         y[feature_idx], 's', label='Target sequence', color='red',\n",
    "    #         markersize=6, markerfacecolor='white', markeredgewidth=1)\n",
    "    plt.plot(len(x[feature_idx]) + 5 - 1,\n",
    "             y[feature_idx], 's', label='Target sequence', color='red',\n",
    "             markersize=6, markerfacecolor='white', markeredgewidth=1)\n",
    "\n",
    "    # Plot groundtruth wave\n",
    "    xygt = torch.cat((xgt, ygt), dim=1)[feature_idx]\n",
    "    plt.plot(range(len(xygt)), xygt,\n",
    "             '-', label='Ground truth', color='gray',\n",
    "             markersize=0, markerfacecolor='white', markeredgewidth=1)\n",
    "\n",
    "\n",
    "    plt.title(f'Example Sine Wave - Feature {feature_idx}')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Add timestamp and user info\n",
    "    timestamp = \"2025-03-01 14:35:23\"\n",
    "    user = \"eric-fey-hus\"\n",
    "    plt.text(0.02, 0.02, f'Generated: {timestamp}\\nUser: {user}',\n",
    "             transform=plt.gca().transAxes, fontsize=8,\n",
    "             bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def create_data_loaders(batch_size=32, n_samples=1000, n_features=15,\n",
    "                       sequence_length=100, prediction_length=5):\n",
    "    \"\"\"Create train, validation, and test data loaders\"\"\"\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = SineWaveDataset(n_samples, n_features, sequence_length, prediction_length)\n",
    "    val_dataset = SineWaveDataset(n_samples//5, n_features, sequence_length, prediction_length, seed=43)\n",
    "    test_dataset = SineWaveDataset(n_samples//5, n_features, sequence_length, prediction_length, seed=44)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def test_model_with_sine_data():\n",
    "    # Parameters\n",
    "    batch_size = 32\n",
    "    n_samples = 1000\n",
    "    n_features = 3\n",
    "    sequence_length = 32\n",
    "    prediction_length = 5\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        batch_size=batch_size,\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        sequence_length=sequence_length,\n",
    "        prediction_length=prediction_length\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    model = DualAttentionModel(\n",
    "        n_features=n_features,\n",
    "        time_steps=sequence_length,\n",
    "        d_model=128,\n",
    "        n_heads=8,\n",
    "        dropout=0.1\n",
    "    )\n",
    "\n",
    "    # Test forward pass\n",
    "    x, y = next(iter(train_loader))\n",
    "    output, feat_attn, time_attn = model(x)\n",
    "\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "    # Plot example\n",
    "    dataset = SineWaveDataset(n_samples, n_features, sequence_length, prediction_length)\n",
    "    plot_example(dataset, sample_idx=1)\n",
    "\n",
    "    return model, train_loader, val_loader, test_loader\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "model, train_loader, val_loader, test_loader = test_model_with_sine_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYxdiQ-nThG6",
    "outputId": "f2e6a3b4-4ea5-4a3e-bb87-2e96b306387e"
   },
   "outputs": [],
   "source": [
    "for x, y in val_loader:\n",
    "  print(x.shape)\n",
    "  print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8pjsOKVNVRj",
    "outputId": "baca0031-e6a0-4eb0-fdf1-b1d6b83a8635"
   },
   "outputs": [],
   "source": [
    "dataset = SineWaveDataset(n_samples=5, n_features=3, sequence_length=5, prediction_length=2)\n",
    "print(dataset[0][0])\n",
    "print(dataset[0][1])\n",
    "print(torch.cat(dataset[0],dim=1))\n",
    "type(torch.cat(dataset[0],dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xWUwP9KAHccL",
    "outputId": "4e6c8f44-a9f1-4848-981c-abbdabee4f53"
   },
   "outputs": [],
   "source": [
    "def train_sine_model(model, train_loader, val_loader, epochs=50, lr=0.001, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output, _, _ = model(x)\n",
    "            #loss = criterion(output, y[:, :, 0])  # Compare with first time step of prediction\n",
    "            loss = criterion(output, y)  # y is only one timepoint 5 or 4 steps ahead\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output, _, _ = model(x)\n",
    "                #val_loss += criterion(output, y[:, :, 0]).item()\n",
    "                val_loss += criterion(output, y).item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_sine_model.pt')\n",
    "\n",
    "# Train the model\n",
    "model, train_loader, val_loader, test_loader = test_model_with_sine_data()\n",
    "train_sine_model(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Yt9UCv6bKJvU",
    "outputId": "f66eba38-d986-49f0-9f13-9dc6578baa4c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def visualize_predictions(model, test_loader, device='cuda', num_examples=3):\n",
    "    model.eval()\n",
    "\n",
    "    # Get some test examples\n",
    "    x, y = next(iter(test_loader))\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        predictions, feat_attn, time_attn = model(x)\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        x = x.cpu().numpy()\n",
    "        y = y.cpu().numpy()\n",
    "\n",
    "    # Plot multiple features for a few examples\n",
    "    for example_idx in range(min(num_examples, x.shape[0])):\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        # Plot 3 different features\n",
    "        for i, feature_idx in enumerate([0,1,2]):#([0, 7, 14]):  # Beginning, middle, and end features\n",
    "            plt.subplot(3, 1, i+1)\n",
    "\n",
    "            # Plot input sequence\n",
    "            time_input = np.arange(x.shape[2])\n",
    "            plt.plot(time_input, x[example_idx, feature_idx],\n",
    "                    label='Input Sequence', color='blue')\n",
    "\n",
    "            # Plot true continuation\n",
    "            #time_target = np.arange(x.shape[2], x.shape[2] + y.shape[2])\n",
    "            time_target = [x.shape[2] + 5 - 1]\n",
    "            plt.plot(time_target, y[example_idx, feature_idx], \"x-\",\n",
    "                    label='True Continuation', color='green')\n",
    "\n",
    "            # Plot prediction\n",
    "            plt.scatter(time_target[0], predictions[example_idx, feature_idx],\n",
    "                       color='red', label='Model Prediction', s=100)\n",
    "\n",
    "            plt.title(f'Example {example_idx + 1}, Feature {feature_idx}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Plot data vs predicted & groundtruth vs predicted\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    # data vs predicted\n",
    "    plt.subplot(1, 2, 1)\n",
    "    print(f\"Data: {y.shape}\")\n",
    "    print(f\"Predictions: {predictions.shape}\")\n",
    "    np.random.seed(1)\n",
    "    for col in range(y.shape[1]):\n",
    "      plt.scatter(predictions[:,col], y[:,col],\n",
    "                  c=np.random.rand(3,), label=f'Feature {col}', alpha=0.5)\n",
    "    # Add perfect line\n",
    "    plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Data vs Predicted')\n",
    "    plt.legend()\n",
    "\n",
    "    # Visualize attention weights\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Feature attention weights\n",
    "    plt.subplot(1, 2, 1)\n",
    "    feat_attn_avg = feat_attn.mean(dim=(0, 1)).cpu().numpy()\n",
    "    plt.imshow(feat_attn_avg, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title('Feature Attention Weights')\n",
    "    plt.xlabel('Target Feature')\n",
    "    plt.ylabel('Source Feature')\n",
    "\n",
    "    # Time attention weights\n",
    "    plt.subplot(1, 2, 2)\n",
    "    time_attn_avg = time_attn.mean(dim=(0, 1)).cpu().numpy()\n",
    "    plt.imshow(time_attn_avg, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title('Time Attention Weights')\n",
    "    plt.xlabel('Target Time Step')\n",
    "    plt.ylabel('Source Time Step')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    total_mse = 0\n",
    "    total_mae = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            predictions, _, _ = model(x)\n",
    "\n",
    "            # Calculate MSE and MAE\n",
    "            #mse = criterion(predictions, y[:, :, 0])\n",
    "            #mae = torch.abs(predictions - y[:, :, 0]).mean()\n",
    "            mse = criterion(predictions, y)\n",
    "            mae = torch.abs(predictions - y).mean()\n",
    "\n",
    "            total_mse += mse.item()\n",
    "            total_mae += mae.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_mse = total_mse / num_batches\n",
    "    avg_mae = total_mae / num_batches\n",
    "\n",
    "    print(f\"Test Set Metrics:\")\n",
    "    print(f\"Average MSE: {avg_mse:.4f}\")\n",
    "    print(f\"Average MAE: {avg_mae:.4f}\")\n",
    "    print(f\"RMSE: {np.sqrt(avg_mse):.4f}\")\n",
    "\n",
    "    return avg_mse, avg_mae\n",
    "\n",
    "def main():\n",
    "    # Parameters\n",
    "    batch_size = 32\n",
    "    n_samples = 1000\n",
    "    n_features = 3\n",
    "    sequence_length = 32\n",
    "    prediction_length = 5\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        batch_size=batch_size,\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        sequence_length=sequence_length,\n",
    "        prediction_length=prediction_length\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = DualAttentionModel(\n",
    "        n_features=n_features,\n",
    "        time_steps=sequence_length,\n",
    "        d_model=128,\n",
    "        n_heads=8,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "    # Load best model weights\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('best_sine_model.pt'))\n",
    "        print(\"Loaded best model weights successfully!\")\n",
    "    except:\n",
    "        print(\"No saved model found. Please train the model first.\")\n",
    "        return\n",
    "\n",
    "    # Evaluate model\n",
    "    mse, mae = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    # Visualize results\n",
    "    visualize_predictions(model, test_loader, device)\n",
    "\n",
    "    # Save a timestamp of when these results were generated\n",
    "    timestamp = \"2025-03-01 10:01:16\"  # Using the provided timestamp\n",
    "    user = \"eric-fey-hus\"\n",
    "\n",
    "    # Save results to a file\n",
    "    with open('model_results.txt', 'w') as f:\n",
    "        f.write(f\"Results generated on: {timestamp}\\n\")\n",
    "        f.write(f\"Generated by user: {user}\\n\")\n",
    "        f.write(f\"Model Performance Metrics:\\n\")\n",
    "        f.write(f\"MSE: {mse:.4f}\\n\")\n",
    "        f.write(f\"MAE: {mae:.4f}\\n\")\n",
    "        f.write(f\"RMSE: {np.sqrt(mse):.4f}\\n\")\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmQzjAuOKAy2"
   },
   "source": [
    "# DEPRECIATED - for learning/reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yph0jcijsX9k",
    "outputId": "3df2ee12-23ac-4300-dfcd-842281ded71a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(-2)]\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        seq_len = query.size(1)\n",
    "\n",
    "        Q = self.W_q(query)\n",
    "        K = self.W_k(key)\n",
    "        V = self.W_v(value)\n",
    "\n",
    "        # Reshape to [batch, heads, seq_len, d_k]\n",
    "        Q = Q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Attention scores\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # Apply attention to V\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "\n",
    "        # Reshape back\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        output = self.W_o(output)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "class DualAttentionModel(nn.Module):\n",
    "    def __init__(self, n_features, time_steps, d_model=128, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(1, d_model)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "\n",
    "        # Feature attention\n",
    "        self.feature_attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.feature_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Time attention\n",
    "        self.time_attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.time_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Output layers\n",
    "        self.fc1 = nn.Linear(d_model, d_model)\n",
    "        self.fc2 = nn.Linear(d_model, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, n_features, time_steps]\n",
    "        batch_size, n_features, time_steps = x.shape\n",
    "\n",
    "        # Add channel dimension and project\n",
    "        x = x.unsqueeze(-1)  # [batch_size, n_features, time_steps, 1]\n",
    "        x = self.input_projection(x)  # [batch_size, n_features, time_steps, d_model]\n",
    "\n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoder(x)\n",
    "\n",
    "        # Prepare for feature attention\n",
    "        # Reshape to [batch_size * time_steps, n_features, d_model]\n",
    "        x_feat = x.transpose(1, 2).reshape(batch_size * time_steps, n_features, self.d_model)\n",
    "\n",
    "        # Feature attention\n",
    "        x_feat, feat_weights = self.feature_attention(x_feat, x_feat, x_feat)\n",
    "\n",
    "        # Reshape back and add residual\n",
    "        x_feat = x_feat.view(batch_size, time_steps, n_features, self.d_model).transpose(1, 2)\n",
    "        x = x + self.dropout(x_feat)\n",
    "        x = self.feature_norm(x)\n",
    "\n",
    "        # Prepare for time attention\n",
    "        # Reshape to [batch_size * n_features, time_steps, d_model]\n",
    "        x_time = x.reshape(batch_size * n_features, time_steps, self.d_model)\n",
    "\n",
    "        # Time attention\n",
    "        x_time, time_weights = self.time_attention(x_time, x_time, x_time)\n",
    "\n",
    "        # Reshape back and add residual\n",
    "        x_time = x_time.view(batch_size, n_features, time_steps, self.d_model)\n",
    "        x = x + self.dropout(x_time)\n",
    "        x = self.time_norm(x)\n",
    "\n",
    "        # Global average pooling over time\n",
    "        x = x.mean(dim=2)  # [batch_size, n_features, d_model]\n",
    "\n",
    "        # Final prediction\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x).squeeze(-1)  # [batch_size, n_features]\n",
    "\n",
    "        return x, feat_weights, time_weights\n",
    "\n",
    "def test_model():\n",
    "    # Example dimensions\n",
    "    batch_size = 32\n",
    "    n_features = 15\n",
    "    time_steps = 10\n",
    "\n",
    "    # Create random input data\n",
    "    x = torch.randn(batch_size, n_features, time_steps)\n",
    "\n",
    "    # Initialize model\n",
    "    model = DualAttentionModel(\n",
    "        n_features=n_features,\n",
    "        time_steps=time_steps,\n",
    "        d_model=128,\n",
    "        n_heads=8,\n",
    "        dropout=0.1\n",
    "    )\n",
    "\n",
    "    # Forward pass\n",
    "    output, feat_attn, time_attn = model(x)\n",
    "\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Feature attention weights shape: {feat_attn.shape}\")\n",
    "    print(f\"Time attention weights shape: {time_attn.shape}\")\n",
    "\n",
    "    return model, output, feat_attn, time_attn\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "model, output, feat_attn, time_attn = test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZxWSywlthth"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fi76QGb_fKNn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask=None, dropout=None):\n",
    "    \"\"\"\n",
    "    Scaled Dot-Product Attention mechanism\n",
    "\n",
    "    Args:\n",
    "        query (Tensor): Query tensor, shape [batch_size, n_heads, seq_len, d_k]\n",
    "        key (Tensor): Key tensor, shape [batch_size, n_heads, seq_len, d_k]\n",
    "        value (Tensor): Value tensor, shape [batch_size, n_heads, seq_len, d_v]\n",
    "        mask (Tensor, optional): Mask tensor, shape [batch_size, 1, seq_len, seq_len]\n",
    "        dropout (nn.Dropout, optional): Dropout layer\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Attention output, shape [batch_size, n_heads, seq_len, d_v]\n",
    "        Tensor: Attention weights, shape [batch_size, n_heads, seq_len, seq_len]\n",
    "    \"\"\"\n",
    "    d_k = query.size(-1)\n",
    "\n",
    "    # Compute attention scores\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    # Apply mask if provided\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "    # Apply softmax to get attention weights\n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        attention_weights = dropout(attention_weights)\n",
    "\n",
    "    # Compute weighted sum of values\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention module\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Model dimension\n",
    "        n_heads (int): Number of attention heads\n",
    "        dropout (float): Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads  # Dimension of each head\n",
    "\n",
    "        # Linear projections\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Linear projections and split into heads\n",
    "        Q = self.W_q(query).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(key).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(value).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Apply mask to all heads if provided\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "\n",
    "        # Apply scaled dot-product attention\n",
    "        output, attention_weights = scaled_dot_product_attention(Q, K, V, mask, self.dropout)\n",
    "\n",
    "        # Concatenate heads and apply final linear projection\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        output = self.W_o(output)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Positional Encoding module to add positional information to embeddings\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Model dimension\n",
    "        max_len (int): Maximum sequence length\n",
    "        dropout (float): Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Create positional encoding matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9h6ZAbbqsWcd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRV_yCYge0jV",
    "outputId": "ee89a74a-2fb5-493d-b78e-0df73e649a38"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "#from attention import MultiHeadAttention, PositionalEncoding\n",
    "\n",
    "# Example parameters\n",
    "batch_size = 32\n",
    "seq_len = 100\n",
    "d_model = 512\n",
    "n_heads = 8\n",
    "\n",
    "# Create sample input\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# Initialize modules\n",
    "pos_encoding = PositionalEncoding(d_model)\n",
    "multihead_attention = MultiHeadAttention(d_model, n_heads)\n",
    "\n",
    "# Add positional encoding\n",
    "x = pos_encoding(x)\n",
    "\n",
    "# Apply multi-head attention (self-attention in this case)\n",
    "output, attention_weights = multihead_attention(x, x, x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")  # [batch_size, seq_len, d_model]\n",
    "print(f\"Attention weights shape: {attention_weights.shape}\")  # [batch_size, n_heads, seq_len, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtwnNoy_g_4l",
    "outputId": "6d22bb74-1b8f-4727-eb74-dcdca91b5fd2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def demonstrate_positional_encoding():\n",
    "    # Example with small numbers for clarity\n",
    "    max_len = 4\n",
    "    d_model = 6\n",
    "\n",
    "    # Create empty positional encoding matrix\n",
    "    pe = torch.zeros(max_len, d_model)\n",
    "    print(\"Initial pe shape:\", pe.shape)\n",
    "    print(\"Initial pe:\\n\", pe)\n",
    "\n",
    "    # Create position vector\n",
    "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "    print(\"\\nPosition shape:\", position.shape)\n",
    "    print(\"Position:\\n\", position)\n",
    "\n",
    "    # Create frequency division terms\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "    print(\"\\nDiv_term shape:\", div_term.shape)\n",
    "    print(\"Div_term:\\n\", div_term)\n",
    "\n",
    "    # Apply sin to even indices\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    print(\"\\nAfter sin (even columns):\\n\", pe)\n",
    "\n",
    "    # Apply cos to odd indices\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    print(\"\\nAfter cos (odd columns):\\n\", pe)\n",
    "\n",
    "    # Add batch dimension\n",
    "    pe = pe.unsqueeze(0)\n",
    "    print(\"\\nFinal shape after unsqueeze:\", pe.shape)\n",
    "    print(\"Final pe:\\n\", pe)\n",
    "\n",
    "demonstrate_positional_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGbXf1QMila4",
    "outputId": "fc6c1e63-cb12-4716-8950-67e791de4338"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def demonstrate_broadcasting():\n",
    "    print(\"1. Basic Broadcasting with Scalars:\")\n",
    "    # A scalar value is broadcast to match the tensor shape\n",
    "    tensor = torch.ones(4, 3)\n",
    "    scalar = 2\n",
    "    result = tensor * scalar\n",
    "    print(f\"Shape of tensor: {tensor.shape}\")  # torch.Size([4, 3])\n",
    "    print(f\"Result shape: {result.shape}\")     # torch.Size([4, 3])\n",
    "    print(f\"Result:\\n{result}\\n\")\n",
    "\n",
    "    print(\"2. Broadcasting Rules with Different Shapes:\")\n",
    "    # Shapes are compared from right to left\n",
    "    # Each dimension must be either:\n",
    "    # 1. Equal, or\n",
    "    # 2. One of them is 1, or\n",
    "    # 3. One doesn't exist\n",
    "\n",
    "    # Example 1: [4, 1] + [3] -> [4, 3]\n",
    "    a = torch.ones(4, 1)\n",
    "    b = torch.arange(3)\n",
    "    result = a + b\n",
    "    print(f\"Shape a: {a.shape}\")        # torch.Size([4, 1])\n",
    "    print(f\"Shape b: {b.shape}\")        # torch.Size([3])\n",
    "    print(f\"Result shape: {result.shape}\")  # torch.Size([4, 3])\n",
    "    print(f\"Result:\\n{result}\\n\")\n",
    "\n",
    "    print(\"3. More Complex Broadcasting:\")\n",
    "    # Example: [2, 1, 3] + [3] -> [2, 1, 3]\n",
    "    x = torch.ones(2, 1, 3)\n",
    "    y = torch.arange(3)\n",
    "    result = x + y\n",
    "    print(f\"Shape x: {x.shape}\")        # torch.Size([2, 1, 3])\n",
    "    print(f\"Shape y: {y.shape}\")        # torch.Size([3])\n",
    "    print(f\"Result shape: {result.shape}\")  # torch.Size([2, 1, 3])\n",
    "    print(f\"Result:\\n{result}\\n\")\n",
    "\n",
    "def show_broadcasting_steps():\n",
    "    \"\"\"\n",
    "    Shows how broadcasting works step by step\n",
    "    \"\"\"\n",
    "    print(\"Broadcasting Steps Visualization:\")\n",
    "\n",
    "    # Original shapes\n",
    "    a = torch.ones(4, 1)    # [4, 1]\n",
    "    b = torch.arange(3)     # [3]\n",
    "\n",
    "    print(\"Step 1: Original shapes\")\n",
    "    print(f\"a shape: {a.shape}\")\n",
    "    print(f\"b shape: {b.shape}\")\n",
    "\n",
    "    # Step 2: Right alignment\n",
    "    print(\"\\nStep 2: Right align dimensions\")\n",
    "    print(\"a: [4, 1]\")\n",
    "    print(\"b:    [3]\")\n",
    "\n",
    "    # Step 3: Broadcasting\n",
    "    print(\"\\nStep 3: Broadcasting\")\n",
    "    print(\"a: [4, 1] -> [4, 3]  (1 is broadcast to 3)\")\n",
    "    print(\"b:    [3] -> [4, 3]  (3 is broadcast across 4 rows)\")\n",
    "\n",
    "    result = a + b\n",
    "    print(f\"\\nFinal result shape: {result.shape}\")\n",
    "\n",
    "# Common broadcasting patterns\n",
    "def common_broadcasting_patterns():\n",
    "    print(\"Common Broadcasting Patterns:\")\n",
    "\n",
    "    # 1. Adding a vector to each row of a matrix\n",
    "    matrix = torch.ones(3, 4)\n",
    "    vector = torch.arange(4)\n",
    "    result1 = matrix + vector\n",
    "    print(f\"1. Matrix {matrix.shape} + Vector {vector.shape} -> {result1.shape}\")\n",
    "\n",
    "    # 2. Adding a column vector to a matrix\n",
    "    col_vector = torch.ones(3, 1)\n",
    "    result2 = matrix + col_vector\n",
    "    print(f\"2. Matrix {matrix.shape} + Column {col_vector.shape} -> {result2.shape}\")\n",
    "\n",
    "    # 3. Outer product using broadcasting\n",
    "    v1 = torch.arange(3).reshape(-1, 1)  # Column vector\n",
    "    v2 = torch.arange(4).reshape(1, -1)  # Row vector\n",
    "    outer_product = v1 * v2\n",
    "    print(f\"3. Outer product: {v1.shape} * {v2.shape} -> {outer_product.shape}\")\n",
    "\n",
    "demonstrate_broadcasting()\n",
    "show_broadcasting_steps()\n",
    "common_broadcasting_patterns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMI5-E3ai71V",
    "outputId": "6b4f2b8a-4e35-4740-bbe6-d3707113148b"
   },
   "outputs": [],
   "source": [
    "    # Original shapes\n",
    "    a = torch.ones(4, 1)    # [4, 1]\n",
    "    b = torch.arange(3)     # [3]\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(a+b)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN5sX4hqdU66P6nGI6DSHeB",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
