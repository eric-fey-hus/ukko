{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to develop own survival heads. Take note to to\n",
    "\n",
    "- [ ] (negative log) partial likelihood (loss function or Cox PH)\n",
    "- [ ] Deal with ties!\n",
    "- [ ] Extras:\n",
    "    - [ ] Baseline hazard and survival curves\n",
    "    - [ ] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import ukko \n",
    "import importlib\n",
    "# For preprocessing\n",
    "print(\"Loading sklearn\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Cox proportional hazards model head.\n",
    "    Outputs hazard ratios instead of binary classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_features, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.risk_score = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)  # log hazard ratio\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Risk score (log hazard ratio)\n",
    "        return torch.exp(self.risk_score(x))  # hazard ratio\n",
    "\n",
    "    \n",
    "def cox_loss(risk_scores, survival_times, events):\n",
    "    \"\"\"\n",
    "    Negative log partial likelihood for Cox model\n",
    "    \n",
    "    Args:\n",
    "        risk_scores: predicted hazard ratios\n",
    "        survival_times: time to event/censoring\n",
    "        events: 1 if event occurred, 0 if censored\n",
    "    \"\"\"\n",
    "    # Sort by survival time\n",
    "    _, indices = torch.sort(survival_times, descending=True)\n",
    "    risk_scores = risk_scores[indices]\n",
    "    events = events[indices]\n",
    "    \n",
    "    # Calculate log partial likelihood\n",
    "    log_risk = torch.log(torch.cumsum(torch.exp(risk_scores), 0))\n",
    "    likelihood = risk_scores - log_risk\n",
    "    \n",
    "    # Mask for events only\n",
    "    return -torch.mean(likelihood * events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalDataset(Dataset):\n",
    "    def __init__(self, features, survival_times, events):\n",
    "        self.features = features\n",
    "        self.times = survival_times    # Time to event/censoring\n",
    "        self.events = events           # Event indicator (1=death, 0=censored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tidy data\n",
    "print(\"Loading tidy data\")\n",
    "df_xy = pd.read_csv(\"data/df_xy_synth_v1.csv\")\n",
    "# IMPUTE nan: -1\n",
    "df_xy = df_xy.fillna(-1)\n",
    "\n",
    "# Define function to convert df into 3-D numpy array\n",
    "def convert_to_3d_df(df):\n",
    "\n",
    "    # Convert column names to tuples, assuming this \"('feature', timepoint)\"\n",
    "    columns = [eval(col) for col in df.columns]\n",
    "    df.columns = columns\n",
    "    \n",
    "    # Extract unique features and timepoints\n",
    "    features = sorted(list(set([col[0] for col in columns])))\n",
    "    timepoints = sorted(list(set([col[1] for col in columns])))\n",
    "    \n",
    "    # Initialize a 3D numpy array\n",
    "    n_rows = df.shape[0]\n",
    "    n_features = len(features)\n",
    "    n_timepoints = len(timepoints)\n",
    "    data_3d = np.empty((n_rows, n_features, n_timepoints))\n",
    "    data_3d.fill(np.nan)\n",
    "    \n",
    "    # Map feature names and timepoints to indices\n",
    "    feature_indices = {feature: i for i, feature in enumerate(features)}\n",
    "    timepoint_indices = {timepoint: i for i, timepoint in enumerate(timepoints)}\n",
    "    \n",
    "    # Fill the 3D array with data from the DataFrame\n",
    "    for col in columns:\n",
    "        feature, timepoint = col\n",
    "        feature_idx = feature_indices[feature]\n",
    "        timepoint_idx = timepoint_indices[timepoint]\n",
    "        data_3d[:, feature_idx, timepoint_idx] = df[col]\n",
    "\n",
    "    # Create a MultiIndex for the columns of the 3D DataFrame\n",
    "    columns = pd.MultiIndex.from_product([features, timepoints], names=[\"Feature\", \"Timepoint\"])\n",
    "    \n",
    "    # Create the 3D DataFrame\n",
    "    df_multiindex = pd.DataFrame(data_3d.reshape(n_rows, -1), columns=columns)\n",
    "    \n",
    "    return df_multiindex, data_3d\n",
    "\n",
    "# Convert AML data to multiindex df\n",
    "df_x, data_3d = convert_to_3d_df(df_xy.iloc[:,3:].fillna(-1))\n",
    "df_y = df_xy.iloc[:,:3]\n",
    "display(df_x)\n",
    "display(df_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Cox PH implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearCoxPH(nn.Module):\n",
    "    \"\"\"\n",
    "    Classical Cox PH with linear predictor: h(t|x) = h₀(t)exp(βx)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.modelname = \"LinearCoxPH\"\n",
    "        self.beta = nn.Linear(n_features, 1, bias=False)  # β coefficients\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.exp(self.beta(x))  # exp(βx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoxPHModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Classical Cox Proportional Hazards model implemented in PyTorch.\n",
    "    Learns a linear combination of features to predict hazard ratios.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, hidden_size=32):\n",
    "        super().__init__()\n",
    "        self.modelname = \"CoxPHModel\"\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Linear hazard prediction\n",
    "        self.hazard_ratio = nn.Sequential(\n",
    "            nn.Linear(n_features, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Compute hazard ratios for each sample.\n",
    "        \n",
    "        Args:\n",
    "            x: Input features [batch_size, n_features]\n",
    "            \n",
    "        Returns:\n",
    "            hazard_ratios: Predicted hazard ratios [batch_size, 1]\n",
    "        \"\"\"\n",
    "        return torch.exp(self.hazard_ratio(x))  # exp(β * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cox_loss(hazard_ratios, durations, events):\n",
    "    \"\"\"\n",
    "    Negative log partial likelihood for Cox model.\n",
    "    \n",
    "    Args:\n",
    "        hazard_ratios: Predicted hazard ratios [batch_size, 1]\n",
    "        durations: Time to event/censoring [batch_size]\n",
    "        events: Event indicators (1=event, 0=censored) [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        loss: Negative log partial likelihood\n",
    "    \"\"\"\n",
    "    # Sort all arrays by duration in descending order\n",
    "    sorted_idx = torch.argsort(durations, descending=True)\n",
    "    hazard_ratios = hazard_ratios[sorted_idx]\n",
    "    events = events[sorted_idx]\n",
    "    \n",
    "    # Calculate log risk (cumulative hazard)\n",
    "    log_risk = torch.logcumsumexp(hazard_ratios.flatten(), dim=0)\n",
    "    \n",
    "    # Select events that contribute to likelihood\n",
    "    event_indices = (events == 1).nonzero().flatten()\n",
    "    \n",
    "    if len(event_indices) == 0:\n",
    "        return torch.tensor(0.0, requires_grad=True)\n",
    "    \n",
    "    # Calculate negative log likelihood\n",
    "    partial_likelihood = hazard_ratios[event_indices].flatten() - log_risk[event_indices]\n",
    "    neg_likelihood = -torch.mean(partial_likelihood)\n",
    "    \n",
    "    return neg_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cox_model(model, train_loader, val_loader, epochs=100, lr=0.001, device='cpu'):\n",
    "    \"\"\"\n",
    "    Train Cox proportional hazards model.\n",
    "    \n",
    "    Args:\n",
    "        model: CoxPHModel instance\n",
    "        train_loader: DataLoader with (features, durations, events)\n",
    "        val_loader: DataLoader with (features, durations, events)\n",
    "        epochs: Number of training epochs\n",
    "        lr: Learning rate\n",
    "        device: 'cuda' or 'cpu'\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    print(f\"Training {model.modelname}\")\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, durations, events in train_loader:\n",
    "            x = x.float().to(device)\n",
    "            durations = durations.float().to(device)\n",
    "            events = events.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            hazard_ratios = model(x)\n",
    "            loss = cox_loss(hazard_ratios, durations, events)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, durations, events in val_loader:\n",
    "                x = x.float().to(device)\n",
    "                durations = durations.float().to(device)\n",
    "                events = events.float().to(device)\n",
    "                \n",
    "                hazard_ratios = model(x)\n",
    "                val_loss += cox_loss(hazard_ratios, durations, events).item()\n",
    "        \n",
    "        # Log metrics\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f\"{model.modelname}.pt\")\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SurvivalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for survival analysis with Cox PH model.\n",
    "    \"\"\"\n",
    "    def __init__(self, features, durations, events):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.durations = torch.FloatTensor(durations)\n",
    "        self.events = torch.FloatTensor(events)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx], \n",
    "                self.durations[idx], \n",
    "                self.events[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test/Example data\n",
    "\n",
    "# from sksurv.datasets import load_veterans_lung_cancer\n",
    "\n",
    "# data_x, data_y = load_veterans_lung_cancer()\n",
    "# data_y\n",
    "\n",
    "from lifelines.datasets import load_regression_dataset\n",
    "regression_dataset = load_regression_dataset() # a Pandas DataFrame\n",
    "regression_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(regression_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Split data\n",
    "df_train = regression_dataset.sample(frac=0.8)\n",
    "df_val = regression_dataset.drop(df_train.index)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SurvivalDataset(\n",
    "    features=df_train.drop(columns=['T', 'E']).values,\n",
    "    durations=df_train['T'].values,\n",
    "    events=df_train['E'].values\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=200, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = SurvivalDataset(\n",
    "    features=df_val.drop(columns=['T', 'E']).values,\n",
    "    durations=df_val['T'].values,\n",
    "    events=df_val['E'].values\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=200, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Define model\n",
    "n_features = 3\n",
    "\n",
    "model = CoxPHModel(n_features=n_features)\n",
    "# Train model\n",
    "history = train_cox_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=150\n",
    ")\n",
    "print(' ')\n",
    "\n",
    "model2 = LinearCoxPH(n_features=n_features)\n",
    "# Train model\n",
    "history = train_cox_model(\n",
    "    model=model2,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=150\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_risk_groups(model, data_loader, device='cpu'):\n",
    "    \"\"\"Get risk scores for all patients and split into high/low risk groups\"\"\"\n",
    "    model.eval()\n",
    "    all_risks = []\n",
    "    all_times = []\n",
    "    all_events = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, durations, events in data_loader:\n",
    "            x = x.float().to(device)\n",
    "            hazard_ratios = model(x)\n",
    "            # Ensure 1D arrays\n",
    "            all_risks.append(hazard_ratios.cpu().numpy().flatten())\n",
    "            all_times.append(durations.numpy().flatten())\n",
    "            all_events.append(events.numpy().flatten())\n",
    "    \n",
    "    # Concatenate all predictions\n",
    "    risk_scores = np.concatenate(all_risks)\n",
    "    times = np.concatenate(all_times)\n",
    "    events = np.concatenate(all_events)\n",
    "    \n",
    "    # Split into high/low risk groups using median\n",
    "    median_risk = np.median(risk_scores)\n",
    "    high_risk = risk_scores >= median_risk\n",
    "    \n",
    "    return risk_scores, times, events, high_risk\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_risk_stratification(times, events, high_risk, title=\"Risk Stratification\"):\n",
    "    \"\"\"Plot Kaplan-Meier curves for high and low risk groups\"\"\"\n",
    "    \n",
    "    # Initialize KM estimator\n",
    "    kmf1 = KaplanMeierFitter()\n",
    "    kmf2 = KaplanMeierFitter()\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot high risk group\n",
    "    mask = high_risk.astype(bool)  # Ensure boolean mask\n",
    "    kmf1.fit(times[mask], events[mask], label='High Risk')\n",
    "    kmf1.plot(show_censors = True, censor_styles={'marker': 'x', 'ms': 15})\n",
    "    \n",
    "    # Plot low risk group\n",
    "    mask = ~high_risk.astype(bool)  # Ensure boolean mask\n",
    "    kmf2.fit(times[mask], events[mask], label='Low Risk')\n",
    "    kmf2.plot(show_censors = True, censor_styles={'marker': 'x', 'ms': 15})\n",
    "    \n",
    "    # Add at-risk counts\n",
    "    lifelines.plotting.add_at_risk_counts(kmf1, kmf2)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Survival Probability')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Add log-rank test\n",
    "    from lifelines.statistics import logrank_test\n",
    "    log_rank = logrank_test(times[high_risk], times[~high_risk],\n",
    "                           events[high_risk], events[~high_risk])\n",
    "    plt.text(0.05, 0.05, f'Log-rank p-value: {log_rank.p_value:.3e}',\n",
    "             transform=plt.gca().transAxes)\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lifelines\n",
    "from lifelines.utils import concordance_index\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load best models\n",
    "best_model = CoxPHModel(n_features=n_features)\n",
    "best_model.load_state_dict(torch.load(f'{model.modelname}.pt'))\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "best_model2 = LinearCoxPH(n_features=n_features)\n",
    "best_model2.load_state_dict(torch.load(f'{model2.modelname}.pt'))\n",
    "best_model2 = best_model2.to(device)\n",
    "\n",
    "# CoxPHModel\n",
    "print(\"CoxPHModel\")\n",
    "# Get risk groups\n",
    "risk_scores, times, events, high_risk = get_risk_groups(best_model, train_loader, device)\n",
    "# Plot Kaplan-Meier curves\n",
    "fig = plot_risk_stratification(times, events, high_risk, \n",
    "                             title=model.modelname)\n",
    "# Add additional metrics\n",
    "c_index = concordance_index(times, -risk_scores.flatten(), events)\n",
    "print(f\"Concordance Index: {c_index:.3f} (1=perfect model)\")\n",
    "\n",
    "# LinearCoxPH\n",
    "print(\"LinearCoxPH\")\n",
    "# Get risk groups\n",
    "risk_scores, times, events, high_risk = get_risk_groups(best_model2, train_loader, device)\n",
    "# Plot Kaplan-Meier curves\n",
    "fig = plot_risk_stratification(times, events, high_risk, \n",
    "                             title=model2.modelname)\n",
    "# Add additional metrics\n",
    "c_index = concordance_index(times, -risk_scores.flatten(), events)\n",
    "print(f\"Concordance Index: {c_index:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision Cox PH from lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_train, duration_col='T', event_col='E')\n",
    "\n",
    "cph.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "risk = cph.predict_partial_hazard(df_train)\n",
    "print (risk)\n",
    "print (np.median(risk))\n",
    "high_risk = risk >= np.median(risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_risk_stratification(df_train['T'], df_train['E'], high_risk, \n",
    "                             title=\"CPH from lifelines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store results\n",
    "results = []\n",
    "\n",
    "# Run 10 times\n",
    "for i in range(15):\n",
    "    # Initialize model\n",
    "    model = LinearCoxPH(n_features=n_features)\n",
    "    \n",
    "    # Train model with existing loaders\n",
    "    history = train_cox_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=100\n",
    "    )    \n",
    "    \n",
    "    # Load best model and get beta coefficients\n",
    "    model.load_state_dict(torch.load(f'{model.modelname}.pt'))\n",
    "    beta = model.beta.weight.detach().cpu().numpy().flatten()\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'run': i+1,\n",
    "        'beta1': beta[0],\n",
    "        'beta2': beta[1],\n",
    "        'beta3': beta[2]\n",
    "    })\n",
    "\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "print(\"\\nMean betas:\")\n",
    "print(results_df[['beta1', 'beta2', 'beta3']].mean())\n",
    "print(\"\\nStd betas:\")\n",
    "print(results_df[['beta1', 'beta2', 'beta3']].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare beta from Cox regression and linear model (including confidence intervals)\n",
    "beta_cph = cph.params_.values   # β coefficients from Cox regression\n",
    "ci_cph = cph.confidence_intervals_.values  # Confidence intervals for β coefficients\n",
    "beta_linear = best_model2.beta.weight.detach().cpu().numpy().flatten()  # β coefficients from linear model \n",
    "print(\"Cox PH β:\", beta_cph)\n",
    "print(\"Linear Model β:\", beta_linear)\n",
    "\n",
    "# Plot β coefficients with confidence intervals\n",
    "plt.figure(figsize=(10, 3)) \n",
    "plot1 = plt.errorbar(beta_cph, range(len(beta_cph)), xerr=(ci_cph[:, 1] - ci_cph[:, 0]) / 2, fmt='o', label='Cox PH', capsize=5)\n",
    "plot2 = plt.errorbar(beta_linear, range(len(beta_linear)), fmt='o', label='Linear Model', capsize=5)\n",
    "for row in range(results_df.shape[0]):\n",
    "    plt.errorbar(results_df.loc[row, ['beta1', 'beta2', 'beta3']], range(0,3), fmt='o', label='Linear Model', capsize=5, c='orange')\n",
    "plt.ylabel('Feature Index')\n",
    "plt.xlabel('β Coefficient')\n",
    "plt.legend([plot1, plot2], ['Cox PH', best_model2.modelname])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
